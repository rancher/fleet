name: E2E Rancher Fleet

on:
  schedule:
    # Run everyday day at 1:00 PM
    - cron:  '0 13 * * *'
  workflow_dispatch:
    inputs:
      ref:
        description: "checkout git branch/tag"
        required: true
        default: "master"
      enable_tmate:
        description: 'Enable debugging via tmate'
        required: false
        default: "false"
  push:
    paths-ignore:
      - 'scripts/**'
      - '*.md'

env:
  GOARCH: amd64
  CGO_ENABLED: 0
  SETUP_GO_VERSION: '^1.18'

jobs:
  rancher-integration:
    runs-on: ubuntu-latest

    steps:
      -
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          ref: ${{ github.event.inputs.ref }}
      -
        uses: actions/setup-go@v3
        with:
          go-version: ${{ env.SETUP_GO_VERSION }}
      -
        uses: actions/cache@v3
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-
      -
        name: Install Ginkgo CLI
        run: go install github.com/onsi/ginkgo/v2/ginkgo@v2.1
      -
        uses: actions/cache@v3
        id: rancher-cli-cache
        with:
          path: /home/runner/.local/bin
          key: ${{ runner.os }}-rancher-cli-2.6.0
      -
        name: Install Rancher CLI
        if: steps.rancher-cli-cache.outputs.cache-hit != 'true'
        run: |
          # download an older CLI to avoid https://github.com/rancher/rancher/issues/37574
          mkdir -p /home/runner/.local/bin
          wget -q https://github.com/rancher/cli/releases/download/v2.6.0/rancher-linux-amd64-v2.6.0.tar.gz
          tar -xz --strip-components=2 -f rancher-linux-amd64-v2.6.0.tar.gz -C /home/runner/.local/bin
          rancher --version
      -
        name: Build fleet binaries
        run: |
          go build -o bin/fleetcontroller-linux-$GOARCH ./cmd/fleetcontroller

          go build -o "bin/fleet-linux-$GOARCH"
          go build -o "bin/fleetagent-linux-$GOARCH" ./cmd/fleetagent
      -
        name: Set up QEMU
        uses: docker/setup-qemu-action@v2
      -
        name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      -
        name: Get uuid
        id: uuid
        run: echo "::set-output name=uuid::$(uuidgen)"
      -
        id: meta-fleet
        uses: docker/metadata-action@v4
        with:
          images: |
            ttl.sh/rancher/fleet-${{ steps.uuid.outputs.uuid }}
          tags: type=raw,value=1h
      -
        uses: docker/build-push-action@v3
        with:
          context: .
          file: package/Dockerfile
          build-args: |
            ARCH=${{ env.GOARCH }}
          push: true
          tags: ${{ steps.meta-fleet.outputs.tags }}
          labels: ${{ steps.meta-fleet.outputs.labels }}
      -
        id: meta-fleet-agent
        uses: docker/metadata-action@v4
        with:
          images: |
            ttl.sh/rancher/fleet-agent-${{ steps.uuid.outputs.uuid }}
          tags: type=raw,value=1h
      -
        uses: docker/build-push-action@v3
        with:
          context: .
          file: package/Dockerfile.agent
          build-args: |
            ARCH=${{ env.GOARCH }}
          push: true
          tags: ${{ steps.meta-fleet-agent.outputs.tags }}
          labels: ${{ steps.meta-fleet-agent.outputs.labels }}
      -
        name: Set up k3d control-plane cluster
        uses: AbsaOSS/k3d-action@v2
        with:
          cluster-name: "upstream"
          args: >-
            -p "80:80@agent:0:direct"
            -p "443:443@agent:0:direct"
            --api-port 6443
            --agents 1
            --k3s-arg '--kubelet-arg=eviction-hard=imagefs.available<1%,nodefs.available<1%@agent:*'
            --k3s-arg '--kubelet-arg=eviction-minimum-reclaim=imagefs.available=1%,nodefs.available=1%@agent:*'
            --network "nw01"
      -
        name: Set up k3d downstream cluster
        uses: AbsaOSS/k3d-action@v2
        with:
          cluster-name: "downstream"
          args: >-
            -p "81:80@agent:0:direct"
            -p "444:443@agent:0:direct"
            --api-port 6644
            --agents 1
            --k3s-arg '--kubelet-arg=eviction-hard=imagefs.available<1%,nodefs.available<1%@agent:*'
            --k3s-arg '--kubelet-arg=eviction-minimum-reclaim=imagefs.available=1%,nodefs.available=1%@agent:*'
            --network "nw01"
      -
        name: Set up tmate debug session
        if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.enable_tmate == 'true' }}
        uses: mxschmitt/action-tmate@v3
        timeout-minutes: 15
        with:
          limit-access-to-actor: true
      -
        name: Set up latest Rancher
        env:
          url: "172.18.0.1.omg.howdoi.website"
          cluster: "k3d-upstream"
        run: |
          ./.github/scripts/setup-latest-rancher.sh
      -
        name: Register Rancher's downstream clusters
        env:
          url: "172.18.0.1.omg.howdoi.website"
        run: |
          kubectl config use-context k3d-upstream
          kubectl cluster-info

          ./.github/scripts/wait-for-loadbalancer.sh
          ./.github/scripts/register-downstream-clusters.sh

          # wait for cluster to settle
          sleep 30
      -
        name: Label downstream cluster
        run: |
          kubectl config use-context k3d-upstream
          ./.github/scripts/label-downstream-cluster.sh
      -
        name: Deploy development fleet
        run: |
          echo "${{ steps.meta-fleet.outputs.tags }} ${{ steps.meta-fleet-agent.outputs.tags }}"
          ./.github/scripts/upgrade-rancher-fleet-to-dev-fleet.sh ${{ steps.meta-fleet.outputs.tags }} ${{ steps.meta-fleet-agent.outputs.tags }}
      -
        name: E2E tests for examples
        env:
          FLEET_E2E_CLUSTER: k3d-upstream
          FLEET_E2E_CLUSTER_DOWNSTREAM: k3d-downstream
        run: |
          kubectl config use-context k3d-upstream
          ginkgo e2e/multi-cluster
      -
        name: Dump failed environment
        if: failure()
        run: |
          mkdir -p tmp
          kubectl config use-context k3d-upstream
          kubectl get -A pod,secret,service,ingress -o json > tmp/cluster.json
          kubectl get -A gitrepos,clusters,clustergroups,bundles,bundledeployments -o json > tmp/fleet.json
          kubectl get -A events > tmp/events.log
          helm list -A > tmp/helm.log
          kubectl logs -n cattle-fleet-system -l app=fleet-controller > tmp/fleetcontroller.log
          kubectl logs -n cattle-fleet-system -l app=fleet-agent > tmp/fleetagent.log

          kubectl config use-context k3d-downstream
          kubectl get -A pod,secret,service,ingress -o json > tmp/cluster-second.json
          kubectl get -A events > tmp/events-downstream.log
          helm list -A > tmp/helm-downstream.log
          kubectl logs -n cattle-fleet-system -l app=fleet-agent > tmp/fleetagent-second.log

          docker logs k3d-upstream-server-0 &> tmp/k3s.log
          docker exec k3d-upstream-server-0 sh -c 'cd /var/log/containers; grep -r "." .' > tmp/containers.log

          docker logs k3d-downstream-server-0 &> tmp/k3s-downstream.log
          docker exec k3d-downstream-server-0 sh -c 'cd /var/log/containers; grep -r "." .' > tmp/containers-downstream.log
      -
        name: Upload logs
        uses: actions/upload-artifact@v3
        if: failure()
        with:
          name: gha-fleet-rancher-logs-${{ github.sha }}-${{ github.run_id }}
          path: |
            tmp/*.json
            tmp/*.log
          retention-days: 2
