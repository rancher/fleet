---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-1-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-1
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI1:=/usr/local/hadoop}

          . $HADOOP_PREFI1/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI1/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI1/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI1/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI1/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI1/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI1/sbin/
            cd $HADOOP_PREFI1/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI1/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI1/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI1/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI1/sbin/
            cd $HADOOP_PREFI1/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI1}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI1}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE1EC_DIR="$bin"/../libexec
          HADOOP_LIBE1EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE1EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE1EC_DIR="$bin"/../libexec
          HADOOP_LIBE1EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE1EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-2-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-2
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI2:=/usr/local/hadoop}

          . $HADOOP_PREFI2/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI2/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI2/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI2/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI2/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI2/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI2/sbin/
            cd $HADOOP_PREFI2/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI2/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI2/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI2/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI2/sbin/
            cd $HADOOP_PREFI2/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI2}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI2}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE2EC_DIR="$bin"/../libexec
          HADOOP_LIBE2EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE2EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE2EC_DIR="$bin"/../libexec
          HADOOP_LIBE2EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE2EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-3-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-3
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI3:=/usr/local/hadoop}

          . $HADOOP_PREFI3/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI3/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI3/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI3/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI3/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI3/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI3/sbin/
            cd $HADOOP_PREFI3/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI3/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI3/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI3/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI3/sbin/
            cd $HADOOP_PREFI3/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI3}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI3}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE3EC_DIR="$bin"/../libexec
          HADOOP_LIBE3EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE3EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE3EC_DIR="$bin"/../libexec
          HADOOP_LIBE3EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE3EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-4-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-4
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI4:=/usr/local/hadoop}

          . $HADOOP_PREFI4/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI4/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI4/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI4/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI4/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI4/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI4/sbin/
            cd $HADOOP_PREFI4/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI4/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI4/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI4/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI4/sbin/
            cd $HADOOP_PREFI4/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI4}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI4}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE4EC_DIR="$bin"/../libexec
          HADOOP_LIBE4EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE4EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE4EC_DIR="$bin"/../libexec
          HADOOP_LIBE4EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE4EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-5-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-5
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI5:=/usr/local/hadoop}

          . $HADOOP_PREFI5/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI5/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI5/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI5/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI5/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI5/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI5/sbin/
            cd $HADOOP_PREFI5/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI5/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI5/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI5/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI5/sbin/
            cd $HADOOP_PREFI5/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI5}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI5}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE5EC_DIR="$bin"/../libexec
          HADOOP_LIBE5EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE5EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE5EC_DIR="$bin"/../libexec
          HADOOP_LIBE5EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE5EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-6-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-6
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI6:=/usr/local/hadoop}

          . $HADOOP_PREFI6/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI6/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI6/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI6/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI6/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI6/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI6/sbin/
            cd $HADOOP_PREFI6/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI6/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI6/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI6/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI6/sbin/
            cd $HADOOP_PREFI6/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI6}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI6}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE6EC_DIR="$bin"/../libexec
          HADOOP_LIBE6EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE6EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE6EC_DIR="$bin"/../libexec
          HADOOP_LIBE6EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE6EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-7-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-7
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI7:=/usr/local/hadoop}

          . $HADOOP_PREFI7/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI7/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI7/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI7/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI7/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI7/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI7/sbin/
            cd $HADOOP_PREFI7/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI7/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI7/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI7/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI7/sbin/
            cd $HADOOP_PREFI7/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI7}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI7}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE7EC_DIR="$bin"/../libexec
          HADOOP_LIBE7EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE7EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE7EC_DIR="$bin"/../libexec
          HADOOP_LIBE7EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE7EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-8-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-8
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI8:=/usr/local/hadoop}

          . $HADOOP_PREFI8/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI8/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI8/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI8/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI8/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI8/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI8/sbin/
            cd $HADOOP_PREFI8/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI8/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI8/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI8/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI8/sbin/
            cd $HADOOP_PREFI8/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI8}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI8}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE8EC_DIR="$bin"/../libexec
          HADOOP_LIBE8EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE8EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE8EC_DIR="$bin"/../libexec
          HADOOP_LIBE8EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE8EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-9-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-9
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI9:=/usr/local/hadoop}

          . $HADOOP_PREFI9/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI9/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI9/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI9/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI9/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI9/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI9/sbin/
            cd $HADOOP_PREFI9/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI9/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI9/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI9/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI9/sbin/
            cd $HADOOP_PREFI9/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI9}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI9}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE9EC_DIR="$bin"/../libexec
          HADOOP_LIBE9EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE9EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE9EC_DIR="$bin"/../libexec
          HADOOP_LIBE9EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE9EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-10-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-10
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI10:=/usr/local/hadoop}

          . $HADOOP_PREFI10/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI10/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI10/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI10/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI10/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI10/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI10/sbin/
            cd $HADOOP_PREFI10/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI10/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI10/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI10/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI10/sbin/
            cd $HADOOP_PREFI10/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI10}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI10}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE10EC_DIR="$bin"/../libexec
          HADOOP_LIBE10EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE10EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE10EC_DIR="$bin"/../libexec
          HADOOP_LIBE10EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE10EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-11-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-11
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI11:=/usr/local/hadoop}

          . $HADOOP_PREFI11/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI11/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI11/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI11/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI11/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI11/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI11/sbin/
            cd $HADOOP_PREFI11/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI11/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI11/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI11/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI11/sbin/
            cd $HADOOP_PREFI11/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI11}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI11}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE11EC_DIR="$bin"/../libexec
          HADOOP_LIBE11EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE11EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE11EC_DIR="$bin"/../libexec
          HADOOP_LIBE11EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE11EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-12-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-12
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI12:=/usr/local/hadoop}

          . $HADOOP_PREFI12/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI12/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI12/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI12/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI12/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI12/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI12/sbin/
            cd $HADOOP_PREFI12/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI12/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI12/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI12/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI12/sbin/
            cd $HADOOP_PREFI12/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI12}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI12}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE12EC_DIR="$bin"/../libexec
          HADOOP_LIBE12EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE12EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE12EC_DIR="$bin"/../libexec
          HADOOP_LIBE12EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE12EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-13-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-13
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI13:=/usr/local/hadoop}

          . $HADOOP_PREFI13/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI13/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI13/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI13/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI13/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI13/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI13/sbin/
            cd $HADOOP_PREFI13/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI13/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI13/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI13/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI13/sbin/
            cd $HADOOP_PREFI13/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI13}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI13}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE13EC_DIR="$bin"/../libexec
          HADOOP_LIBE13EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE13EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE13EC_DIR="$bin"/../libexec
          HADOOP_LIBE13EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE13EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-14-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-14
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI14:=/usr/local/hadoop}

          . $HADOOP_PREFI14/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI14/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI14/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI14/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI14/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI14/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI14/sbin/
            cd $HADOOP_PREFI14/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI14/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI14/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI14/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI14/sbin/
            cd $HADOOP_PREFI14/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI14}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI14}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE14EC_DIR="$bin"/../libexec
          HADOOP_LIBE14EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE14EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE14EC_DIR="$bin"/../libexec
          HADOOP_LIBE14EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE14EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-15-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-15
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI15:=/usr/local/hadoop}

          . $HADOOP_PREFI15/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI15/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI15/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI15/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI15/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI15/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI15/sbin/
            cd $HADOOP_PREFI15/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI15/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI15/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI15/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI15/sbin/
            cd $HADOOP_PREFI15/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI15}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI15}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE15EC_DIR="$bin"/../libexec
          HADOOP_LIBE15EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE15EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE15EC_DIR="$bin"/../libexec
          HADOOP_LIBE15EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE15EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-16-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-16
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI16:=/usr/local/hadoop}

          . $HADOOP_PREFI16/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI16/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI16/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI16/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI16/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI16/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI16/sbin/
            cd $HADOOP_PREFI16/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI16/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI16/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI16/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI16/sbin/
            cd $HADOOP_PREFI16/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI16}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI16}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE16EC_DIR="$bin"/../libexec
          HADOOP_LIBE16EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE16EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE16EC_DIR="$bin"/../libexec
          HADOOP_LIBE16EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE16EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-17-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-17
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI17:=/usr/local/hadoop}

          . $HADOOP_PREFI17/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI17/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI17/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI17/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI17/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI17/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI17/sbin/
            cd $HADOOP_PREFI17/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI17/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI17/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI17/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI17/sbin/
            cd $HADOOP_PREFI17/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI17}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI17}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE17EC_DIR="$bin"/../libexec
          HADOOP_LIBE17EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE17EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE17EC_DIR="$bin"/../libexec
          HADOOP_LIBE17EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE17EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-18-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-18
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI18:=/usr/local/hadoop}

          . $HADOOP_PREFI18/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI18/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI18/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI18/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI18/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI18/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI18/sbin/
            cd $HADOOP_PREFI18/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI18/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI18/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI18/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI18/sbin/
            cd $HADOOP_PREFI18/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI18}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI18}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE18EC_DIR="$bin"/../libexec
          HADOOP_LIBE18EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE18EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE18EC_DIR="$bin"/../libexec
          HADOOP_LIBE18EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE18EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-19-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-19
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI19:=/usr/local/hadoop}

          . $HADOOP_PREFI19/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI19/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI19/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI19/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI19/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI19/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI19/sbin/
            cd $HADOOP_PREFI19/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI19/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI19/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI19/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI19/sbin/
            cd $HADOOP_PREFI19/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI19}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI19}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE19EC_DIR="$bin"/../libexec
          HADOOP_LIBE19EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE19EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE19EC_DIR="$bin"/../libexec
          HADOOP_LIBE19EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE19EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-20-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-20
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI20:=/usr/local/hadoop}

          . $HADOOP_PREFI20/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI20/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI20/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI20/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI20/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI20/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI20/sbin/
            cd $HADOOP_PREFI20/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI20/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI20/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI20/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI20/sbin/
            cd $HADOOP_PREFI20/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI20}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI20}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE20EC_DIR="$bin"/../libexec
          HADOOP_LIBE20EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE20EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE20EC_DIR="$bin"/../libexec
          HADOOP_LIBE20EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE20EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-21-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-21
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI21:=/usr/local/hadoop}

          . $HADOOP_PREFI21/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI21/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI21/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI21/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI21/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI21/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI21/sbin/
            cd $HADOOP_PREFI21/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI21/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI21/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI21/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI21/sbin/
            cd $HADOOP_PREFI21/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI21}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI21}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE21EC_DIR="$bin"/../libexec
          HADOOP_LIBE21EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE21EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE21EC_DIR="$bin"/../libexec
          HADOOP_LIBE21EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE21EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-22-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-22
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI22:=/usr/local/hadoop}

          . $HADOOP_PREFI22/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI22/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI22/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI22/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI22/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI22/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI22/sbin/
            cd $HADOOP_PREFI22/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI22/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI22/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI22/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI22/sbin/
            cd $HADOOP_PREFI22/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI22}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI22}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE22EC_DIR="$bin"/../libexec
          HADOOP_LIBE22EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE22EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE22EC_DIR="$bin"/../libexec
          HADOOP_LIBE22EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE22EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-23-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-23
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI23:=/usr/local/hadoop}

          . $HADOOP_PREFI23/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI23/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI23/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI23/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI23/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI23/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI23/sbin/
            cd $HADOOP_PREFI23/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI23/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI23/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI23/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI23/sbin/
            cd $HADOOP_PREFI23/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI23}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI23}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE23EC_DIR="$bin"/../libexec
          HADOOP_LIBE23EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE23EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE23EC_DIR="$bin"/../libexec
          HADOOP_LIBE23EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE23EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-24-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-24
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI24:=/usr/local/hadoop}

          . $HADOOP_PREFI24/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI24/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI24/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI24/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI24/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI24/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI24/sbin/
            cd $HADOOP_PREFI24/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI24/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI24/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI24/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI24/sbin/
            cd $HADOOP_PREFI24/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI24}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI24}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE24EC_DIR="$bin"/../libexec
          HADOOP_LIBE24EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE24EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE24EC_DIR="$bin"/../libexec
          HADOOP_LIBE24EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE24EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-25-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-25
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI25:=/usr/local/hadoop}

          . $HADOOP_PREFI25/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI25/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI25/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI25/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI25/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI25/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI25/sbin/
            cd $HADOOP_PREFI25/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI25/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI25/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI25/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI25/sbin/
            cd $HADOOP_PREFI25/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI25}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI25}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE25EC_DIR="$bin"/../libexec
          HADOOP_LIBE25EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE25EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE25EC_DIR="$bin"/../libexec
          HADOOP_LIBE25EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE25EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-26-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-26
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI26:=/usr/local/hadoop}

          . $HADOOP_PREFI26/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI26/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI26/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI26/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI26/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI26/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI26/sbin/
            cd $HADOOP_PREFI26/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI26/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI26/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI26/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI26/sbin/
            cd $HADOOP_PREFI26/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI26}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI26}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE26EC_DIR="$bin"/../libexec
          HADOOP_LIBE26EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE26EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE26EC_DIR="$bin"/../libexec
          HADOOP_LIBE26EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE26EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-27-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-27
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI27:=/usr/local/hadoop}

          . $HADOOP_PREFI27/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI27/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI27/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI27/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI27/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI27/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI27/sbin/
            cd $HADOOP_PREFI27/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI27/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI27/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI27/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI27/sbin/
            cd $HADOOP_PREFI27/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI27}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI27}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE27EC_DIR="$bin"/../libexec
          HADOOP_LIBE27EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE27EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE27EC_DIR="$bin"/../libexec
          HADOOP_LIBE27EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE27EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-28-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-28
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI28:=/usr/local/hadoop}

          . $HADOOP_PREFI28/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI28/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI28/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI28/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI28/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI28/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI28/sbin/
            cd $HADOOP_PREFI28/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI28/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI28/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI28/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI28/sbin/
            cd $HADOOP_PREFI28/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI28}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI28}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE28EC_DIR="$bin"/../libexec
          HADOOP_LIBE28EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE28EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE28EC_DIR="$bin"/../libexec
          HADOOP_LIBE28EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE28EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-29-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-29
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI29:=/usr/local/hadoop}

          . $HADOOP_PREFI29/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI29/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI29/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI29/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI29/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI29/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI29/sbin/
            cd $HADOOP_PREFI29/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI29/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI29/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI29/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI29/sbin/
            cd $HADOOP_PREFI29/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI29}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI29}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE29EC_DIR="$bin"/../libexec
          HADOOP_LIBE29EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE29EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE29EC_DIR="$bin"/../libexec
          HADOOP_LIBE29EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE29EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-30-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-30
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI30:=/usr/local/hadoop}

          . $HADOOP_PREFI30/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI30/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI30/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI30/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI30/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI30/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI30/sbin/
            cd $HADOOP_PREFI30/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI30/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI30/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI30/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI30/sbin/
            cd $HADOOP_PREFI30/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI30}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI30}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE30EC_DIR="$bin"/../libexec
          HADOOP_LIBE30EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE30EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE30EC_DIR="$bin"/../libexec
          HADOOP_LIBE30EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE30EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-31-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-31
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI31:=/usr/local/hadoop}

          . $HADOOP_PREFI31/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI31/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI31/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI31/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI31/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI31/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI31/sbin/
            cd $HADOOP_PREFI31/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI31/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI31/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI31/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI31/sbin/
            cd $HADOOP_PREFI31/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI31}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI31}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE31EC_DIR="$bin"/../libexec
          HADOOP_LIBE31EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE31EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE31EC_DIR="$bin"/../libexec
          HADOOP_LIBE31EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE31EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-32-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-32
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI32:=/usr/local/hadoop}

          . $HADOOP_PREFI32/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI32/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI32/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI32/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI32/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI32/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI32/sbin/
            cd $HADOOP_PREFI32/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI32/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI32/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI32/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI32/sbin/
            cd $HADOOP_PREFI32/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI32}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI32}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE32EC_DIR="$bin"/../libexec
          HADOOP_LIBE32EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE32EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE32EC_DIR="$bin"/../libexec
          HADOOP_LIBE32EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE32EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-33-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-33
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI33:=/usr/local/hadoop}

          . $HADOOP_PREFI33/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI33/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI33/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI33/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI33/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI33/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI33/sbin/
            cd $HADOOP_PREFI33/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI33/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI33/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI33/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI33/sbin/
            cd $HADOOP_PREFI33/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI33}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI33}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE33EC_DIR="$bin"/../libexec
          HADOOP_LIBE33EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE33EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE33EC_DIR="$bin"/../libexec
          HADOOP_LIBE33EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE33EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-34-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-34
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI34:=/usr/local/hadoop}

          . $HADOOP_PREFI34/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI34/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI34/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI34/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI34/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI34/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI34/sbin/
            cd $HADOOP_PREFI34/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI34/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI34/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI34/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI34/sbin/
            cd $HADOOP_PREFI34/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI34}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI34}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE34EC_DIR="$bin"/../libexec
          HADOOP_LIBE34EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE34EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE34EC_DIR="$bin"/../libexec
          HADOOP_LIBE34EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE34EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-35-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-35
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI35:=/usr/local/hadoop}

          . $HADOOP_PREFI35/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI35/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI35/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI35/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI35/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI35/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI35/sbin/
            cd $HADOOP_PREFI35/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI35/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI35/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI35/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI35/sbin/
            cd $HADOOP_PREFI35/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI35}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI35}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE35EC_DIR="$bin"/../libexec
          HADOOP_LIBE35EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE35EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE35EC_DIR="$bin"/../libexec
          HADOOP_LIBE35EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE35EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-36-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-36
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI36:=/usr/local/hadoop}

          . $HADOOP_PREFI36/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI36/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI36/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI36/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI36/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI36/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI36/sbin/
            cd $HADOOP_PREFI36/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI36/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI36/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI36/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI36/sbin/
            cd $HADOOP_PREFI36/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI36}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI36}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE36EC_DIR="$bin"/../libexec
          HADOOP_LIBE36EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE36EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE36EC_DIR="$bin"/../libexec
          HADOOP_LIBE36EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE36EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-37-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-37
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI37:=/usr/local/hadoop}

          . $HADOOP_PREFI37/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI37/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI37/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI37/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI37/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI37/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI37/sbin/
            cd $HADOOP_PREFI37/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI37/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI37/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI37/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI37/sbin/
            cd $HADOOP_PREFI37/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI37}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI37}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE37EC_DIR="$bin"/../libexec
          HADOOP_LIBE37EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE37EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE37EC_DIR="$bin"/../libexec
          HADOOP_LIBE37EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE37EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-38-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-38
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI38:=/usr/local/hadoop}

          . $HADOOP_PREFI38/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI38/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI38/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI38/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI38/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI38/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI38/sbin/
            cd $HADOOP_PREFI38/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI38/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI38/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI38/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI38/sbin/
            cd $HADOOP_PREFI38/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI38}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI38}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE38EC_DIR="$bin"/../libexec
          HADOOP_LIBE38EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE38EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE38EC_DIR="$bin"/../libexec
          HADOOP_LIBE38EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE38EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-39-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-39
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI39:=/usr/local/hadoop}

          . $HADOOP_PREFI39/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI39/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI39/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI39/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI39/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI39/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI39/sbin/
            cd $HADOOP_PREFI39/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI39/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI39/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI39/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI39/sbin/
            cd $HADOOP_PREFI39/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI39}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI39}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE39EC_DIR="$bin"/../libexec
          HADOOP_LIBE39EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE39EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE39EC_DIR="$bin"/../libexec
          HADOOP_LIBE39EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE39EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-40-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-40
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI40:=/usr/local/hadoop}

          . $HADOOP_PREFI40/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI40/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI40/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI40/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI40/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI40/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI40/sbin/
            cd $HADOOP_PREFI40/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI40/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI40/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI40/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI40/sbin/
            cd $HADOOP_PREFI40/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI40}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI40}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE40EC_DIR="$bin"/../libexec
          HADOOP_LIBE40EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE40EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE40EC_DIR="$bin"/../libexec
          HADOOP_LIBE40EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE40EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-41-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-41
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI41:=/usr/local/hadoop}

          . $HADOOP_PREFI41/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI41/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI41/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI41/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI41/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI41/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI41/sbin/
            cd $HADOOP_PREFI41/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI41/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI41/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI41/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI41/sbin/
            cd $HADOOP_PREFI41/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI41}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI41}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE41EC_DIR="$bin"/../libexec
          HADOOP_LIBE41EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE41EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE41EC_DIR="$bin"/../libexec
          HADOOP_LIBE41EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE41EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-42-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-42
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI42:=/usr/local/hadoop}

          . $HADOOP_PREFI42/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI42/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI42/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI42/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI42/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI42/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI42/sbin/
            cd $HADOOP_PREFI42/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI42/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI42/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI42/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI42/sbin/
            cd $HADOOP_PREFI42/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI42}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI42}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE42EC_DIR="$bin"/../libexec
          HADOOP_LIBE42EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE42EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE42EC_DIR="$bin"/../libexec
          HADOOP_LIBE42EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE42EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-43-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-43
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI43:=/usr/local/hadoop}

          . $HADOOP_PREFI43/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI43/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI43/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI43/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI43/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI43/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI43/sbin/
            cd $HADOOP_PREFI43/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI43/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI43/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI43/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI43/sbin/
            cd $HADOOP_PREFI43/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI43}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI43}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE43EC_DIR="$bin"/../libexec
          HADOOP_LIBE43EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE43EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE43EC_DIR="$bin"/../libexec
          HADOOP_LIBE43EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE43EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-44-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-44
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI44:=/usr/local/hadoop}

          . $HADOOP_PREFI44/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI44/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI44/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI44/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI44/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI44/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI44/sbin/
            cd $HADOOP_PREFI44/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI44/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI44/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI44/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI44/sbin/
            cd $HADOOP_PREFI44/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI44}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI44}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE44EC_DIR="$bin"/../libexec
          HADOOP_LIBE44EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE44EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE44EC_DIR="$bin"/../libexec
          HADOOP_LIBE44EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE44EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-45-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-45
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI45:=/usr/local/hadoop}

          . $HADOOP_PREFI45/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI45/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI45/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI45/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI45/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI45/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI45/sbin/
            cd $HADOOP_PREFI45/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI45/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI45/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI45/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI45/sbin/
            cd $HADOOP_PREFI45/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI45}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI45}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE45EC_DIR="$bin"/../libexec
          HADOOP_LIBE45EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE45EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE45EC_DIR="$bin"/../libexec
          HADOOP_LIBE45EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE45EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-46-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-46
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI46:=/usr/local/hadoop}

          . $HADOOP_PREFI46/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI46/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI46/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI46/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI46/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI46/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI46/sbin/
            cd $HADOOP_PREFI46/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI46/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI46/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI46/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI46/sbin/
            cd $HADOOP_PREFI46/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI46}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI46}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE46EC_DIR="$bin"/../libexec
          HADOOP_LIBE46EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE46EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE46EC_DIR="$bin"/../libexec
          HADOOP_LIBE46EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE46EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-47-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-47
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI47:=/usr/local/hadoop}

          . $HADOOP_PREFI47/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI47/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI47/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI47/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI47/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI47/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI47/sbin/
            cd $HADOOP_PREFI47/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI47/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI47/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI47/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI47/sbin/
            cd $HADOOP_PREFI47/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI47}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI47}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE47EC_DIR="$bin"/../libexec
          HADOOP_LIBE47EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE47EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE47EC_DIR="$bin"/../libexec
          HADOOP_LIBE47EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE47EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-48-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-48
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI48:=/usr/local/hadoop}

          . $HADOOP_PREFI48/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI48/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI48/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI48/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI48/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI48/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI48/sbin/
            cd $HADOOP_PREFI48/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI48/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI48/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI48/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI48/sbin/
            cd $HADOOP_PREFI48/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI48}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI48}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE48EC_DIR="$bin"/../libexec
          HADOOP_LIBE48EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE48EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE48EC_DIR="$bin"/../libexec
          HADOOP_LIBE48EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE48EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-49-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-49
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI49:=/usr/local/hadoop}

          . $HADOOP_PREFI49/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI49/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI49/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI49/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI49/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI49/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI49/sbin/
            cd $HADOOP_PREFI49/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI49/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI49/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI49/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI49/sbin/
            cd $HADOOP_PREFI49/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI49}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI49}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE49EC_DIR="$bin"/../libexec
          HADOOP_LIBE49EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE49EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE49EC_DIR="$bin"/../libexec
          HADOOP_LIBE49EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE49EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
---
apiVersion: fleet.cattle.io/v1alpha1
kind: Bundle
metadata:
  name: create-50-bundle
  labels:
    fleet.cattle.io/commit: 269ad1f41bd40bf9f2df9dec571fcc299ecf5c94
    fleet.cattle.io/benchmark-group: create-50-bundle
spec:
  resources:
  - content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: test-config-10kb-50
      data:
        bootstrap.sh: |
          #!/bin/bash

          : ${HADOOP_PREFI50:=/usr/local/hadoop}

          . $HADOOP_PREFI50/etc/hadoop/hadoop-env.sh

          # Directory to find config artifacts
          CONFIG_DIR="/tmp/hadoop-config"

          # Copy config files from volume mount

          for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
            if [[ -e ${CONFIG_DIR}/$f ]]; then
              cp ${CONFIG_DIR}/$f $HADOOP_PREFI50/etc/hadoop/$f
            else
              echo "ERROR: Could not find $f in $CONFIG_DIR"
              exit 1
            fi
          done

          # installing libraries if any - (resource urls added comma separated to the ACP system variable)
          cd $HADOOP_PREFI50/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

          if [[ "${HOSTNAME}" =~ "hdfs-nn" ]]; then
            mkdir -p /root/hdfs/namenode
            $HADOOP_PREFI50/bin/hdfs namenode -format -force -nonInteractive
            $HADOOP_PREFI50/sbin/hadoop-daemon.sh start namenode
          fi

          if [[ "${HOSTNAME}" =~ "hdfs-dn" ]]; then
            mkdir -p /root/hdfs/datanode

            #  wait up to 30 seconds for namenode
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-hdfs-nn:50070` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-hdfs-nn" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for hdfs-nn, exiting." && exit 1

            $HADOOP_PREFI50/sbin/hadoop-daemon.sh start datanode
          fi

          if [[ "${HOSTNAME}" =~ "yarn-rm" ]]; then
            cp ${CONFIG_DIR}/start-yarn-rm.sh $HADOOP_PREFI50/sbin/
            cd $HADOOP_PREFI50/sbin
            chmod +x start-yarn-rm.sh
            ./start-yarn-rm.sh
          fi

          if [[ "${HOSTNAME}" =~ "yarn-nm" ]]; then
            sed -i '/<\/configuration>/d' $HADOOP_PREFI50/etc/hadoop/yarn-site.xml
            cat >> $HADOOP_PREFI50/etc/hadoop/yarn-site.xml <<- EOM
            <property>
              <name>yarn.nodemanager.resource.memory-mb</name>
              <value>${MY_MEM_LIMIT:-2048}</value>
            </property>

            <property>
              <name>yarn.nodemanager.resource.cpu-vcores</name>
              <value>${MY_CPU_LIMIT:-2}</value>
            </property>
          EOM
            echo '</configuration>' >> $HADOOP_PREFI50/etc/hadoop/yarn-site.xml
            cp ${CONFIG_DIR}/start-yarn-nm.sh $HADOOP_PREFI50/sbin/
            cd $HADOOP_PREFI50/sbin
            chmod +x start-yarn-nm.sh

            #  wait up to 30 seconds for resourcemanager
            (while [[ $count -lt 15 && -z `curl -sf http://foo-hadoop-yarn-rm:8088/ws/v1/cluster/info` ]]; do ((count=count+1)) ; echo "Waiting for foo-hadoop-yarn-rm" ; sleep 2; done && [[ $count -lt 15 ]])
            [[ $? -ne 0 ]] && echo "Timeout waiting for yarn-rm, exiting." && exit 1

            ./start-yarn-nm.sh
          fi

          if [[ $1 == "-d" ]]; then
            until find ${HADOOP_PREFI50}/logs -mmin -1 | egrep -q '.*'; echo "`date`: Waiting for logs..." ; do sleep 2 ; done
            tail -F ${HADOOP_PREFI50}/logs/* &
            while true; do sleep 1000; done
          fi

          if [[ $1 == "-bash" ]]; then
            /bin/bash
          fi
        core-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration>
            <property>
                  <name>fs.defaultFS</name>
                  <value>hdfs://foo-hadoop-hdfs-nn:9000/</value>
                  <description>NameNode URI</description>
              </property>
          </configuration>
        hdfs-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
          <configuration><property>
              <name>dfs.datanode.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.client.use.datanode.hostname</name>
              <value>false</value>
            </property>

            <property>
              <name>dfs.replication</name>
                <value>3</value>
            </property>

            <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///root/hdfs/datanode</value>
              <description>DataNode directory</description>
            </property>

            <property>
              <name>dfs.namenode.name.dir</name>
              <value>file:///root/hdfs/namenode</value>
              <description>NameNode directory for namespace and transaction logs storage.</description>
            </property>

            <property>
              <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
              <value>false</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>dfs.namenode.rpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>dfs.namenode.servicerpc-bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

          </configuration>
        mapred-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:10020</value>
            </property>
            <property>
              <name>mapreduce.jobhistory.webapp.address</name>
              <value>foo-hadoop-yarn-rm-0.foo-hadoop-yarn-rm.default.svc.cluster.local:19888</value>
            </property>
          </configuration>
        slaves: 'localhost

      '
        start-yarn-nm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE50EC_DIR="$bin"/../libexec
          HADOOP_LIBE50EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE50EC_DIR/yarn-config.sh

          # start resourceManager
          # "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          #"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        start-yarn-rm.sh: |
          #!/usr/bin/env bash

          # Licensed to the Apache Software Foundation (ASF) under one or more
          # contributor license agreements.  See the NOTICE file distributed with
          # this work for additional information regarding copyright ownership.
          # The ASF licenses this file to You under the Apache License, Version 2.0
          # (the "License"); you may not use this file except in compliance with
          # the License.  You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.


          # Start all yarn daemons.  Run this on master node.

          echo "starting yarn daemons"

          bin=`dirname "${BASH_SOURCE-$0}"`
          bin=`cd "$bin"; pwd`

          DEFAULT_LIBE50EC_DIR="$bin"/../libexec
          HADOOP_LIBE50EC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
          . $HADOOP_LIBE50EC_DIR/yarn-config.sh

          # start resourceManager
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager
          # start nodeManager
          # "$bin"/yarn-daemons.sh --config $YARN_CONF_DIR  start nodemanager
          # start proxyserver
          "$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start proxyserver
        yarn-site.xml: |
          <?xml version="1.0"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

          <configuration>
            <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>foo-hadoop-yarn-rm</value>
            </property>

            <!-- Bind to all interfaces -->
            <property>
              <name>yarn.resourcemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.nodemanager.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <property>
              <name>yarn.timeline-service.bind-host</name>
              <value>0.0.0.0</value>
            </property>
            <!-- /Bind to all interfaces -->

            <property>
              <name>yarn.nodemanager.vmem-check-enabled</name>
              <value>false</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>

            <property>
              <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>

            <property>
              <description>List of directories to store localized files in.</description>
              <name>yarn.nodemanager.local-dirs</name>
              <value>/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir</value>
            </property>

            <property>
              <description>Where to store container logs.</description>
              <name>yarn.nodemanager.log-dirs</name>
              <value>/var/log/hadoop-yarn/containers</value>
            </property>

            <property>
              <description>Where to aggregate logs to.</description>
              <name>yarn.nodemanager.remote-app-log-dir</name>
              <value>/var/log/hadoop-yarn/apps</value>
            </property>

            <property>
              <name>yarn.application.classpath</name>
              <value>
                /usr/local/hadoop/etc/hadoop,
                /usr/local/hadoop/share/hadoop/common/*,
                /usr/local/hadoop/share/hadoop/common/lib/*,
                /usr/local/hadoop/share/hadoop/hdfs/*,
                /usr/local/hadoop/share/hadoop/hdfs/lib/*,
                /usr/local/hadoop/share/hadoop/mapreduce/*,
                /usr/local/hadoop/share/hadoop/mapreduce/lib/*,
                /usr/local/hadoop/share/hadoop/yarn/*,
                /usr/local/hadoop/share/hadoop/yarn/lib/*
              </value>
            </property>
          </configuration>
    name: configmap.yaml
  targets:
    - clusterSelector:
        matchLabels:
          fleet.cattle.io/benchmark: "true"
