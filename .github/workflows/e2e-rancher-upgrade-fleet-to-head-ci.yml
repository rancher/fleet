# Upgrade fleet in latest Rancher to dev version and run MC tests
name: E2E Upgrade Fleet in Rancher To HEAD

on:
  schedule:
    # Run everyday day at 1:00 PM
    - cron:  '0 13 * * *'
  workflow_dispatch:
    inputs:
      ref:
        description: "checkout git branch/tag"
        required: true
        default: "main"
  push:
    tags: [ 'v*' ]
    paths-ignore:
      - '*.md'

env:
  GOARCH: amd64
  CGO_ENABLED: 0
  SETUP_K3D_VERSION: 'v5.7.4'
  SETUP_K3S_VERSION: 'v1.31.1-k3s1'

jobs:
  rancher-fleet-integration:
    runs-on: ubuntu-latest

    steps:
      -
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event.inputs.ref }}
      -
        uses: actions/setup-go@v5
        with:
          go-version-file: 'go.mod'
          check-latest: true
      -
        name: Install Ginkgo CLI
        run: go install github.com/onsi/ginkgo/v2/ginkgo
      -
        name: Install crust-gather CLI
        run: curl -sSfL https://github.com/crust-gather/crust-gather/raw/main/install.sh | sh -s -- --yes
      -
        uses: actions/cache@v4
        id: rancher-cli-cache
        with:
          path: /home/runner/.local/bin
          key: ${{ runner.os }}-rancher-cli-2.6.0
      -
        name: Install Rancher CLI
        if: steps.rancher-cli-cache.outputs.cache-hit != 'true'
        run: |
          # download an older CLI to avoid https://github.com/rancher/rancher/issues/37574
          mkdir -p /home/runner/.local/bin
          wget -q https://github.com/rancher/cli/releases/download/v2.6.0/rancher-linux-amd64-v2.6.0.tar.gz
          tar -xz --strip-components=2 -f rancher-linux-amd64-v2.6.0.tar.gz -C /home/runner/.local/bin
          rancher --version
      -
        name: Build fleet binaries
        run: |
          ./.github/scripts/build-fleet-binaries.sh
      -
        name: Set up QEMU
        uses: docker/setup-qemu-action@v3
      -
        name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      -
        name: Get uuid
        id: uuid
        run: echo "::set-output name=uuid::$(uuidgen)"
      -
        id: meta-fleet
        uses: docker/metadata-action@v5
        with:
          images: |
            ttl.sh/rancher/fleet-${{ steps.uuid.outputs.uuid }}
          tags: type=raw,value=1h
      -
        uses: docker/build-push-action@v6
        with:
          context: .
          file: package/Dockerfile
          build-args: |
            ARCH=${{ env.GOARCH }}
          push: true
          tags: ${{ steps.meta-fleet.outputs.tags }}
          labels: ${{ steps.meta-fleet.outputs.labels }}
      -
        id: meta-fleet-agent
        uses: docker/metadata-action@v5
        with:
          images: |
            ttl.sh/rancher/fleet-agent-${{ steps.uuid.outputs.uuid }}
          tags: type=raw,value=1h
      -
        uses: docker/build-push-action@v6
        with:
          context: .
          file: package/Dockerfile.agent
          build-args: |
            ARCH=${{ env.GOARCH }}
          push: true
          tags: ${{ steps.meta-fleet-agent.outputs.tags }}
          labels: ${{ steps.meta-fleet-agent.outputs.labels }}
      -
        name: Set up k3d control-plane cluster
        uses: AbsaOSS/k3d-action@v2
        with:
          k3d-version: ${{ env.SETUP_K3D_VERSION }}
          cluster-name: "upstream"
          args: >-
            -p "80:80@agent:0:direct"
            -p "443:443@agent:0:direct"
            --api-port 6443
            --agents 1
            --k3s-arg '--kubelet-arg=eviction-hard=imagefs.available<1%,nodefs.available<1%@agent:*'
            --k3s-arg '--kubelet-arg=eviction-minimum-reclaim=imagefs.available=1%,nodefs.available=1%@agent:*'
            --network "nw01"
            --image docker.io/rancher/k3s:${{ env.SETUP_K3S_VERSION }}
      -
        name: Set up k3d downstream cluster
        uses: AbsaOSS/k3d-action@v2
        with:
          k3d-version: ${{ env.SETUP_K3D_VERSION }}
          cluster-name: "downstream"
          args: >-
            -p "81:80@agent:0:direct"
            -p "444:443@agent:0:direct"
            --api-port 6644
            --agents 1
            --k3s-arg '--kubelet-arg=eviction-hard=imagefs.available<1%,nodefs.available<1%@agent:*'
            --k3s-arg '--kubelet-arg=eviction-minimum-reclaim=imagefs.available=1%,nodefs.available=1%@agent:*'
            --network "nw01"
            --image docker.io/rancher/k3s:${{ env.SETUP_K3S_VERSION }}
      -
        name: Set up latest Rancher
        env:
          public_hostname: "172.18.0.1.sslip.io"
        run: |
          ./.github/scripts/setup-latest-rancher.sh
      -
        name: Register Rancher's downstream clusters
        env:
          public_hostname: "172.18.0.1.sslip.io"
        run: |
          ./.github/scripts/wait-for-loadbalancer.sh
          ./.github/scripts/register-downstream-clusters.sh

          # wait for cluster to settle
          sleep 30

          ./.github/scripts/label-downstream-cluster.sh
      -
        name: Create example workload
        run: |
          kubectl apply -n fleet-local -f e2e/assets/fleet-upgrade/gitrepo-simple.yaml
          kubectl apply -n fleet-default -f e2e/assets/fleet-upgrade/gitrepo-simple.yaml
          # wait for bundle ready
          until kubectl get bundles -n fleet-local test-simple-simple-chart -o=jsonpath='{.status.conditions[?(@.type=="Ready")].status}' | grep -q "True"; do sleep 3; done
          until kubectl get bundles -n fleet-default test-simple-simple-chart -o=jsonpath='{.status.conditions[?(@.type=="Ready")].status}' | grep -q "True"; do sleep 3; done
      -
        name: Deploy development fleet
        run: |
          echo "${{ steps.meta-fleet.outputs.tags }} ${{ steps.meta-fleet-agent.outputs.tags }}"
          ./.github/scripts/upgrade-rancher-fleet-to-dev-fleet.sh ${{ steps.meta-fleet.outputs.tags }} ${{ steps.meta-fleet-agent.outputs.tags }}
      -
        name: E2E tests for examples
        env:
          FLEET_E2E_NS: fleet-local
          FLEET_E2E_NS_DOWNSTREAM: fleet-default
        run: |
          kubectl config use-context k3d-upstream
          ginkgo --github-output e2e/multi-cluster
      -
        name: Dump Failed Downstream Environment
        if: failure()
        run: |
          kubectl config use-context k3d-downstream
          crust-gather collect --exclude-namespace=kube-system --exclude-kind=Lease --duration=5s -f tmp/downstream
      -
        name: Upload logs
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: gha-fleet-rancher-logs-${{ github.sha }}-${{ github.run_id }}
          path: |
            tmp/downstream
            tmp/upstream
          retention-days: 2
